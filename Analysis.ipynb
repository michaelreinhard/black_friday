{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a link to the data: [Black Friday](https://www.kaggle.com/mehdidag/black-friday). Here is the original posting of the data set from [Analytics Vidhya](https://datahack.analyticsvidhya.com/contest/black-friday/#problem_statement). The data is from Indian department stores and is posted on the website for use in a contest. The contest is to predict purchases and that will be one of the business questions I analyze in this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "zip_ref = zipfile.ZipFile(\"BlackFriday.csv.zip\", 'r')\n",
    "zip_ref.extractall()\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('BlackFriday.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_ID</th>\n",
       "      <th>Product_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>City_Category</th>\n",
       "      <th>Stay_In_Current_City_Years</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Product_Category_1</th>\n",
       "      <th>Product_Category_2</th>\n",
       "      <th>Product_Category_3</th>\n",
       "      <th>Purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000001</td>\n",
       "      <td>P00069042</td>\n",
       "      <td>F</td>\n",
       "      <td>0-17</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000001</td>\n",
       "      <td>P00248942</td>\n",
       "      <td>F</td>\n",
       "      <td>0-17</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000001</td>\n",
       "      <td>P00087842</td>\n",
       "      <td>F</td>\n",
       "      <td>0-17</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000001</td>\n",
       "      <td>P00085442</td>\n",
       "      <td>F</td>\n",
       "      <td>0-17</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000002</td>\n",
       "      <td>P00285442</td>\n",
       "      <td>M</td>\n",
       "      <td>55+</td>\n",
       "      <td>16</td>\n",
       "      <td>C</td>\n",
       "      <td>4+</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User_ID Product_ID Gender   Age  Occupation City_Category  \\\n",
       "0  1000001  P00069042      F  0-17          10             A   \n",
       "1  1000001  P00248942      F  0-17          10             A   \n",
       "2  1000001  P00087842      F  0-17          10             A   \n",
       "3  1000001  P00085442      F  0-17          10             A   \n",
       "4  1000002  P00285442      M   55+          16             C   \n",
       "\n",
       "  Stay_In_Current_City_Years  Marital_Status  Product_Category_1  \\\n",
       "0                          2               0                   3   \n",
       "1                          2               0                   1   \n",
       "2                          2               0                  12   \n",
       "3                          2               0                  12   \n",
       "4                         4+               0                   8   \n",
       "\n",
       "   Product_Category_2  Product_Category_3  Purchase  \n",
       "0                 NaN                 NaN      8370  \n",
       "1                 6.0                14.0     15200  \n",
       "2                 NaN                 NaN      1422  \n",
       "3                14.0                 NaN      1057  \n",
       "4                 NaN                 NaN      7969  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(537577, 12)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Wrangling\n",
    "As this data was taken from a contest it is, in the main, ready for analysis, but there are a few things that need to be done to it. The missing values have to be dealt with and some variables need their type adjusted.\n",
    "### Missing Values\n",
    "First I look for missing values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User_ID                       0\n",
      "Product_ID                    0\n",
      "Gender                        0\n",
      "Age                           0\n",
      "Occupation                    0\n",
      "City_Category                 0\n",
      "Stay_In_Current_City_Years    0\n",
      "Marital_Status                0\n",
      "Product_Category_1            0\n",
      "Product_Category_2            0\n",
      "Product_Category_3            0\n",
      "Purchase                      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The missing values appear to be in the Product Categories 2 and 3. My guess is that these are the subcategories of product 1 so when they are missing I will just the product category 1.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#substitue Product Category 1 for missing data in 2 and 3\n",
    "df['Product_Category_2'] = df['Product_Category_2'].fillna(\n",
    "    df['Product_Category_1']) \n",
    "df['Product_Category_3'] = df['Product_Category_3'].fillna(\n",
    "    df['Product_Category_1']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mis-Typed data\n",
    "There are some data that have the wrong type. For instance a is presently coded as a string variable becuase of the categories, like '0-17', '55+', it was coded into. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Age'] = df['Age'].replace(\n",
    "    {'0-17':int(15), \n",
    "     '55+':int(65),\n",
    "     '18-25':int(22),\n",
    "     '26-35':int(31),\n",
    "     '36-45':int(41),\n",
    "     '46-50':int(48),\n",
    "     '51-55':int(53)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same is true for the number of years spent in current city, though this variable only codes up to a maximum of 4 years. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     2\n",
       "1     2\n",
       "2     2\n",
       "3     2\n",
       "4    4+\n",
       "Name: Stay_In_Current_City_Years, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Stay_In_Current_City_Years'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn into an integer \n",
    "df['Stay_In_Current_City_Years'] = df['Stay_In_Current_City_Years'].replace(\n",
    "    {'0':int(0), \n",
    "     '1':int(1), \n",
    "     '2':int(2), \n",
    "     '3':int(3), \n",
    "     '4+':int(4)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answering Business Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Occupation\n",
       "0     9186.946726\n",
       "1     9017.703095\n",
       "2     9025.938982\n",
       "3     9238.077277\n",
       "4     9279.026742\n",
       "5     9388.848978\n",
       "6     9336.378620\n",
       "7     9502.175276\n",
       "8     9576.508530\n",
       "9     8714.335934\n",
       "10    9052.836410\n",
       "11    9299.467190\n",
       "12    9883.052460\n",
       "13    9424.449391\n",
       "14    9568.536426\n",
       "15    9866.239925\n",
       "16    9457.133118\n",
       "17    9906.378997\n",
       "18    9233.671418\n",
       "19    8754.249162\n",
       "20    8881.099514\n",
       "Name: Purchase, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('Occupation')['Purchase'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    A\n",
       "1    A\n",
       "2    A\n",
       "3    A\n",
       "4    C\n",
       "Name: City_Category, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['City_Category'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "City_Category\n",
       "A    8958.011014\n",
       "B    9198.657848\n",
       "C    9844.441855\n",
       "Name: Purchase, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('City_Category')['Purchase'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there is a marginal difference between the cities and the amount of purchases people make. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gender\n",
       "F    8809.761349\n",
       "M    9504.771713\n",
       "Name: Purchase, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('Gender')['Purchase'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Marital_Status\n",
       "0    9333.325467\n",
       "1    9334.632681\n",
       "Name: Purchase, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('Marital_Status')['Purchase'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gender  Marital_Status\n",
       "F       0                 8753.809299\n",
       "        1                 8887.751553\n",
       "M       0                 9518.540223\n",
       "        1                 9484.617891\n",
       "Name: Purchase, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['Gender', 'Marital_Status'])['Purchase'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Product_Category_1  Gender\n",
       "1                   F         13597.502561\n",
       "                    M         13609.885434\n",
       "2                   F         11408.887314\n",
       "                    M         11208.050485\n",
       "3                   F         10261.916071\n",
       "                    M         10027.457317\n",
       "4                   F          2456.584267\n",
       "                    M          2271.799625\n",
       "5                   F          6305.995607\n",
       "                    M          6211.920553\n",
       "6                   F         15604.922235\n",
       "                    M         15904.344381\n",
       "7                   F         16416.834052\n",
       "                    M         16359.265328\n",
       "8                   F          7498.937415\n",
       "                    M          7496.696382\n",
       "9                   F         15724.314286\n",
       "                    M         15499.311377\n",
       "10                  F         19679.803163\n",
       "                    M         19680.024397\n",
       "11                  F          4669.676540\n",
       "                    M          4686.133620\n",
       "12                  F          1424.203741\n",
       "                    M          1305.235492\n",
       "13                  F           733.248599\n",
       "                    M           718.836241\n",
       "14                  F         13759.174551\n",
       "                    M         12721.312289\n",
       "15                  F         14696.352884\n",
       "                    M         14792.235135\n",
       "16                  F         14678.643250\n",
       "                    M         14791.709981\n",
       "17                  F          9840.180328\n",
       "                    M         10194.567194\n",
       "18                  F          2859.265957\n",
       "                    M          2991.473509\n",
       "Name: Purchase, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['Product_Category_1','Gender'])['Purchase'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "City_Category  Gender\n",
       "A              F          8630.771856\n",
       "               M          9061.717739\n",
       "B              F          8590.518480\n",
       "               M          9400.754481\n",
       "C              F          9264.964642\n",
       "               M         10033.197730\n",
       "Name: Purchase, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['City_Category', 'Gender'])['Purchase'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Product_Category_1\n",
       "1     13607.701495\n",
       "2     11255.680752\n",
       "3     10096.841705\n",
       "4      2328.862886\n",
       "5      6238.004045\n",
       "6     15837.893573\n",
       "7     16373.830153\n",
       "8      7497.354850\n",
       "9     15538.297030\n",
       "10    19679.974364\n",
       "11     4682.933556\n",
       "12     1351.195613\n",
       "13      722.619485\n",
       "14    13145.452000\n",
       "15    14776.422215\n",
       "16    14764.157471\n",
       "17    10156.440917\n",
       "18     2975.307642\n",
       "Name: Purchase, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('Product_Category_1')['Purchase'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Product_Category_2\n",
       "2.0     13621.740682\n",
       "3.0     11229.532628\n",
       "4.0     10218.319009\n",
       "5.0      9034.054649\n",
       "6.0     11500.585872\n",
       "7.0      6877.234146\n",
       "8.0     10278.036363\n",
       "9.0      7282.593633\n",
       "10.0    15656.014711\n",
       "11.0     8935.682467\n",
       "12.0     6968.662299\n",
       "13.0     9672.264346\n",
       "14.0     7106.356752\n",
       "15.0    10358.723290\n",
       "16.0    10298.676025\n",
       "17.0     9416.534196\n",
       "18.0     9370.698168\n",
       "Name: Purchase, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('Product_Category_2')['Purchase'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Product_Category_2\n",
       "1.0     13074.182210\n",
       "2.0     13593.102752\n",
       "3.0     11270.842243\n",
       "4.0     10172.640202\n",
       "5.0      6957.587072\n",
       "6.0     11672.275160\n",
       "7.0     15028.773457\n",
       "8.0      8931.445486\n",
       "9.0      7284.591738\n",
       "10.0    16264.057301\n",
       "11.0     6947.495583\n",
       "12.0     5594.340728\n",
       "13.0     9168.505962\n",
       "14.0     7216.709266\n",
       "15.0    10704.883258\n",
       "16.0    11126.641638\n",
       "17.0     9447.163320\n",
       "18.0     5982.959001\n",
       "Name: Purchase, dtype: float64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('Product_Category_2')['Purchase'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Product_Category_3\n",
       "3.0     13957.166667\n",
       "4.0      9778.290761\n",
       "5.0     12128.351770\n",
       "6.0     13189.812785\n",
       "8.0     13029.554102\n",
       "9.0     10429.594533\n",
       "10.0    13522.985866\n",
       "11.0    12112.626622\n",
       "12.0     8718.752144\n",
       "13.0    13183.002228\n",
       "14.0    10053.965179\n",
       "15.0    12338.232770\n",
       "16.0    11982.500093\n",
       "17.0    11779.470059\n",
       "18.0    10983.583169\n",
       "Name: Purchase, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('Product_Category_3')['Purchase'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Stay_In_Current_City_Years</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Product_Category_1</th>\n",
       "      <th>Product_Category_2</th>\n",
       "      <th>Product_Category_3</th>\n",
       "      <th>Purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.375770e+05</td>\n",
       "      <td>537577.000000</td>\n",
       "      <td>537577.00000</td>\n",
       "      <td>537577.000000</td>\n",
       "      <td>537577.000000</td>\n",
       "      <td>537577.000000</td>\n",
       "      <td>537577.000000</td>\n",
       "      <td>537577.000000</td>\n",
       "      <td>537577.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.002992e+06</td>\n",
       "      <td>35.197002</td>\n",
       "      <td>8.08271</td>\n",
       "      <td>1.859458</td>\n",
       "      <td>0.408797</td>\n",
       "      <td>5.295546</td>\n",
       "      <td>9.159668</td>\n",
       "      <td>8.329471</td>\n",
       "      <td>9333.859853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.714393e+03</td>\n",
       "      <td>11.262886</td>\n",
       "      <td>6.52412</td>\n",
       "      <td>1.289828</td>\n",
       "      <td>0.491612</td>\n",
       "      <td>3.750701</td>\n",
       "      <td>4.795474</td>\n",
       "      <td>4.760436</td>\n",
       "      <td>4981.022133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000001e+06</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>185.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.001495e+06</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5866.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.003031e+06</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>7.00000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8062.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.004417e+06</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>14.00000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12073.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.006040e+06</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>20.00000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>23961.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            User_ID            Age    Occupation  Stay_In_Current_City_Years  \\\n",
       "count  5.375770e+05  537577.000000  537577.00000               537577.000000   \n",
       "mean   1.002992e+06      35.197002       8.08271                    1.859458   \n",
       "std    1.714393e+03      11.262886       6.52412                    1.289828   \n",
       "min    1.000001e+06      15.000000       0.00000                    0.000000   \n",
       "25%    1.001495e+06      31.000000       2.00000                    1.000000   \n",
       "50%    1.003031e+06      31.000000       7.00000                    2.000000   \n",
       "75%    1.004417e+06      41.000000      14.00000                    3.000000   \n",
       "max    1.006040e+06      65.000000      20.00000                    4.000000   \n",
       "\n",
       "       Marital_Status  Product_Category_1  Product_Category_2  \\\n",
       "count   537577.000000       537577.000000       537577.000000   \n",
       "mean         0.408797            5.295546            9.159668   \n",
       "std          0.491612            3.750701            4.795474   \n",
       "min          0.000000            1.000000            1.000000   \n",
       "25%          0.000000            1.000000            5.000000   \n",
       "50%          0.000000            5.000000            8.000000   \n",
       "75%          1.000000            8.000000           14.000000   \n",
       "max          1.000000           18.000000           18.000000   \n",
       "\n",
       "       Product_Category_3       Purchase  \n",
       "count       537577.000000  537577.000000  \n",
       "mean             8.329471    9333.859853  \n",
       "std              4.760436    4981.022133  \n",
       "min              1.000000     185.000000  \n",
       "25%              5.000000    5866.000000  \n",
       "50%              8.000000    8062.000000  \n",
       "75%             12.000000   12073.000000  \n",
       "max             18.000000   23961.000000  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep for machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Purchase']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a function to drop unused categories\n",
    "def drop_col(df, use_product_factor=False, category=False):\n",
    "    '''drop categories that are unused, making User_ID \n",
    "       and Product_ID optional and making Product_Category_ID optional'''\n",
    "    \n",
    "    if use_product_factor:   \n",
    "        my_list = ['Purchase', 'User_ID', 'Product_ID']\n",
    "    else:\n",
    "        my_list = ['Purchase']\n",
    "    if category:\n",
    "        my_list.extend(['Product_Category_1', 'Product_Category_2', 'Product_Category_3'])\n",
    "    for col in my_list:\n",
    "        try:\n",
    "            df.drop(col, inplace=True, axis=1)\n",
    "        except:\n",
    "            'column has already been deleted'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_col(df, use_product_factor=False, category=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list = ['Occupation', 'Marital_Status', 'Gender', 'City_Category']\n",
    "\n",
    "\n",
    "def select_qual_var(df, my_list, Product_ID=False, Product_Category=True):\n",
    "    '''creates list of qualitative variables. Includes product category and\n",
    "    excludes Product_ID by default'''\n",
    "    \n",
    "    if Product_ID==True:\n",
    "        my_list.append('Product_ID')\n",
    "    if Product_Category==True:\n",
    "        my_list.extend(['Product_Category_1', 'Product_Category_2', 'Product_Category_3'])\n",
    "    df_qual = df.loc[:, my_list]\n",
    "    \n",
    "    return df_qual\n",
    "\n",
    "df_qual = select_qual_var(df, my_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make dummy variables of the qualitative variables\n",
    "#and drop the original variable\n",
    "for var in df_qual.columns:\n",
    "    df_qual = pd.concat(\n",
    "                [df_qual.drop(var, axis=1), \n",
    "                 pd.get_dummies(df_qual[var], \n",
    "                   drop_first=True, \n",
    "                   prefix=var, \n",
    "                   prefix_sep='_')], \n",
    "                 axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(537577, 75)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_qual.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_quant = df.select_dtypes(['float', 'int'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['User_ID', 'Age', 'Occupation', 'Stay_In_Current_City_Years',\n",
       "       'Marital_Status', 'Product_Category_1', 'Product_Category_2',\n",
       "       'Product_Category_3'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_quant.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_quant.join(df_qual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_split(df, y, sample=False):\n",
    "    '''performs train_test_split with option to \n",
    "    create a smaller sample data set of 5000.'''\n",
    "    \n",
    "    if sample:\n",
    "        df = df.sample(n=5000, random_state=42)\n",
    "        y = y.sample(n=5000, random_state=42)\n",
    "    \n",
    "    X = df\n",
    "    y = y\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=42)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = get_train_test_split(df, y, sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()  \n",
    "X_train = sc.fit_transform(X_train)  \n",
    "X_test = sc.transform(X_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6165549193561138\n",
      "3009.3818159443094\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression(normalize=True)\n",
    "lr.fit(X_train, y_train)\n",
    "y_test_pred = lr.predict(X_test)\n",
    "\n",
    "print(r2_score(y_test, y_test_pred))\n",
    "print(np.sqrt(mean_squared_error(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 28 candidates, totalling 84 fits\n",
      "Ridge(alpha=20, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=42, solver='lsqr', tol=0.001)\n",
      "0.6127170504411876\n",
      "{'alpha': 20, 'solver': 'lsqr'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  84 out of  84 | elapsed:    3.4s finished\n"
     ]
    }
   ],
   "source": [
    "params={'solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga'] , \\\n",
    "        'alpha': [1, 5, 10, 20]}\n",
    "ridge = GridSearchCV(Ridge(random_state=42), param_grid=params, cv=3, verbose=1, n_jobs=-1)\n",
    "results = ridge.fit(X_train, y_train)\n",
    "print(results.best_estimator_)\n",
    "print(results.best_score_)\n",
    "print(results.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6229504064751438\n",
      "2984.179521057263\n"
     ]
    }
   ],
   "source": [
    "ridge = Ridge(alpha=10, random_state=42)\n",
    "ridge.fit(X_train, y_train)\n",
    "y_test_pred = ridge.predict(X_test)\n",
    "\n",
    "print(r2_score(y_test, y_test_pred))\n",
    "print(np.sqrt(mean_squared_error(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So running grid search does nothing for the ridge regression. Well, not nothing. We increased our R^2 from 0.63598581 to 0.63598589. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 7 candidates, totalling 21 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  14 out of  21 | elapsed:    0.4s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  21 out of  21 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso(alpha=30, copy_X=True, fit_intercept=True, max_iter=10000,\n",
      "   normalize=False, positive=False, precompute=False, random_state=42,\n",
      "   selection='cyclic', tol=0.001, warm_start=False)\n",
      "0.6153468328677617\n",
      "{'alpha': 30}\n"
     ]
    }
   ],
   "source": [
    "params={'alpha': [30, 35, 40, 45, 50, 55, 60]}\n",
    "lasso = GridSearchCV(Lasso(random_state=42, max_iter=10000, tol=0.001), param_grid=params, \\\n",
    "                     cv=3, verbose=1, n_jobs=-1)\n",
    "results = lasso.fit(X_train, y_train)\n",
    "\n",
    "print(results.best_estimator_)\n",
    "print(results.best_score_)\n",
    "print(results.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6251221570018113\n",
      "2975.57289107943\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = lasso.predict(X_test)\n",
    "print(r2_score(y_test, y_test_pred))\n",
    "print(np.sqrt(mean_squared_error(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so that is another trivial improvement. I am going to try it one more time with some different values for the alpha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6241978957630061\n",
      "2979.2387700661425\n"
     ]
    }
   ],
   "source": [
    "lasso = Lasso(random_state=42, alpha=10)\n",
    "lasso.fit(X_train, y_train)\n",
    "y_test_pred = lasso.predict(X_test)\n",
    "\n",
    "print(r2_score(y_test, y_test_pred))\n",
    "print(np.sqrt(mean_squared_error(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={'max_depth':[12],'max_leaf_nodes': [300],'max_features':[29], 'min_samples_leaf': [4],'n_estimators' :[400]}\n",
    "cv = GridSearchCV(estimator=RandomForestRegressor(random_state=42), param_grid=params, verbose=1, cv=3, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed: 14.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.909085869789124\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "results = cv.fit(X_train,y_train)\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "total = t1 - t0\n",
    "print(total/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=12,\n",
      "           max_features=29, max_leaf_nodes=300, min_impurity_decrease=0.0,\n",
      "           min_impurity_split=None, min_samples_leaf=4,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           n_estimators=400, n_jobs=1, oob_score=False, random_state=42,\n",
      "           verbose=0, warm_start=False)\n",
      "0.6506366033925587\n",
      "{'max_depth': 12, 'max_features': 29, 'max_leaf_nodes': 300, 'min_samples_leaf': 4, 'n_estimators': 400}\n",
      "0.6482557365667088\n",
      "2953.767805895894\n"
     ]
    }
   ],
   "source": [
    "print(results.best_estimator_)\n",
    "print(results.best_score_)\n",
    "print(results.best_params_)\n",
    "y_test_pred = cv.predict(X_test)\n",
    "\n",
    "print(r2_score(y_test, y_test_pred))\n",
    "print(np.sqrt(mean_squared_error(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "0.6396446905743249  \n",
    "{'max_depth': 10, 'max_features': 60, 'max_leaf_nodes': 28, 'min_samples_leaf': 1}\n",
    "\n",
    "\n",
    "0.6402419530153179  \n",
    "{'max_depth': 10, 'max_features': 60, 'max_leaf_nodes': 30, 'min_samples_leaf': 1}  \n",
    "0.6374292705606246  \n",
    "2998.8808516148197  \n",
    "\n",
    "0.6405342111257681  \n",
    "{'max_depth': 10, 'max_features': 60, 'max_leaf_nodes': 32, 'min_samples_leaf': 1}  \n",
    "0.6373198347718354  \n",
    "2999.3333979793224  \n",
    "\n",
    "0.6421043640764094  \n",
    "{'max_depth': 10, 'max_features': 60, 'max_leaf_nodes': 37, 'min_samples_leaf': 1}  \n",
    "0.639996982546654  \n",
    "2988.243004415205  \n",
    "\n",
    "0.6434113088026432  \n",
    "{'max_depth': 10, 'max_features': 60, 'max_leaf_nodes': 43, 'min_samples_leaf': 1}  \n",
    "0.6411755176459013  \n",
    "2983.347717301678  \n",
    "\n",
    "0.6552352176633882  \n",
    "{'max_depth': 21, 'max_features': 69, 'max_leaf_nodes': 695, 'min_samples_leaf': 1, 'n_estimators': 400}  \n",
    "0.6540011743719747  \n",
    "2929.544864410299  \n",
    "\n",
    "0.652088718311206  \n",
    "{'max_depth': 21, 'max_features': 69, 'max_leaf_nodes': 695, 'min_samples_leaf': 1, 'n_estimators': 500}  \n",
    "0.6507284171033074  \n",
    "2943.3673443800467 \n",
    "\n",
    "0.6506366033925587  \n",
    "{'max_depth': 12, 'max_features': 29, 'max_leaf_nodes': 300, 'min_samples_leaf': 4, 'n_estimators': 400}  \n",
    "0.6482557365667088  \n",
    "2953.767805895894  \n",
    "\n",
    "### With sample of 5000 from the data\n",
    "\n",
    "0.6094743953931943  \n",
    "{'max_depth': 12, 'max_features': 39, 'max_leaf_nodes': 400, 'min_samples_leaf': 4, 'n_estimators': 500}  \n",
    "0.6187989290334923  \n",
    "3000.563094011314  \n",
    "\n",
    "0.6112096122872844  \n",
    "{'max_depth': 12, 'max_features': 29, 'max_leaf_nodes': 300, 'min_samples_leaf': 4, 'n_estimators': 400}  \n",
    "0.6188284074127202  \n",
    "3000.447074601107  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
